{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 12510185,
     "sourceType": "datasetVersion",
     "datasetId": 7896173
    }
   ],
   "dockerImageVersionId": 31041,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Attack the classifier of the last layer of Phi 3 model for one prompt at a time"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from custom_model import CustomModel\n",
    "from opt_utils import get_nonascii_toks, token_gradients, sample_control, get_filtered_cands, get_logits, load_model_and_tokenizer, get_prompt, get_primary_activation\n",
    "from suffix_manager import SuffixManager\n",
    "\n",
    "np.set_printoptions(suppress=True, linewidth=10000)\n",
    "torch.set_printoptions(sci_mode=False, linewidth=100000, threshold=float('inf'))"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-20T19:33:08.087665Z",
     "iopub.execute_input": "2025-07-20T19:33:08.087850Z",
     "iopub.status.idle": "2025-07-20T19:33:26.620877Z",
     "shell.execute_reply.started": "2025-07-20T19:33:08.087833Z",
     "shell.execute_reply": "2025-07-20T19:33:26.620055Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T09:42:25.416543Z",
     "start_time": "2025-07-24T09:42:25.413634Z"
    }
   },
   "cell_type": "code",
   "source": "model_path = 'loaded_models/phi3'",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "adv_string_init = \"! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\"\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "prompt_index = 0\n",
    "\n",
    "num_steps = 100\n",
    "topk = 64\n",
    "batch_size = 64\n",
    "allow_non_ascii = False  # you can set this to True to use unicode tokens"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-20T19:33:26.621832Z",
     "iopub.execute_input": "2025-07-20T19:33:26.622262Z",
     "iopub.status.idle": "2025-07-20T19:33:26.626379Z",
     "shell.execute_reply.started": "2025-07-20T19:33:26.622228Z",
     "shell.execute_reply": "2025-07-20T19:33:26.625691Z"
    },
    "ExecuteTime": {
     "end_time": "2025-07-24T09:42:25.469667Z",
     "start_time": "2025-07-24T09:42:25.467162Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T09:42:25.519799Z",
     "start_time": "2025-07-24T09:42:25.517485Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# Get the text from the test dataset\n",
    "text = get_prompt(prompt_index)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-20T19:33:26.677368Z",
     "iopub.execute_input": "2025-07-20T19:33:26.678107Z",
     "iopub.status.idle": "2025-07-20T19:33:26.700064Z",
     "shell.execute_reply.started": "2025-07-20T19:33:26.678082Z",
     "shell.execute_reply": "2025-07-20T19:33:26.699410Z"
    },
    "ExecuteTime": {
     "end_time": "2025-07-24T09:42:26.304019Z",
     "start_time": "2025-07-24T09:42:25.570672Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "model, tokenizer = load_model_and_tokenizer(model_path)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-20T19:33:26.700824Z",
     "iopub.execute_input": "2025-07-20T19:33:26.701035Z",
     "iopub.status.idle": "2025-07-20T19:34:44.179917Z",
     "shell.execute_reply.started": "2025-07-20T19:33:26.701018Z",
     "shell.execute_reply": "2025-07-20T19:34:44.179368Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-24T09:42:26.316883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "807529e710d94f9f9bf87cd3d6f4b963"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T09:42:29.571854282Z",
     "start_time": "2025-07-24T09:38:04.242404Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.device)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "suffix_manager = SuffixManager(tokenizer, text, adv_string_init)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-20T19:34:44.180673Z",
     "iopub.execute_input": "2025-07-20T19:34:44.181263Z",
     "iopub.status.idle": "2025-07-20T19:34:44.184865Z",
     "shell.execute_reply.started": "2025-07-20T19:34:44.181200Z",
     "shell.execute_reply": "2025-07-20T19:34:44.184178Z"
    },
    "ExecuteTime": {
     "end_time": "2025-07-24T09:42:31.013296591Z",
     "start_time": "2025-07-24T09:38:04.307670Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-20T19:34:46.949159Z",
     "iopub.execute_input": "2025-07-20T19:34:46.949520Z",
     "iopub.status.idle": "2025-07-20T19:34:48.219522Z",
     "shell.execute_reply.started": "2025-07-20T19:34:46.949492Z",
     "shell.execute_reply": "2025-07-20T19:34:48.218703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "linear_model = pickle.load(open('./Task Drift/trained_linear_probes_microsoft/phi3/31/model.pickle', 'rb'))\n",
    "\n",
    "custom_model = CustomModel(model, linear_model)\n",
    "device = custom_model.base_model.get_input_embeddings().weight.device"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T09:42:31.017259285Z",
     "start_time": "2025-07-24T09:05:36.864226Z"
    }
   },
   "cell_type": "code",
   "source": "print(device)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-20T19:41:28.395726Z",
     "iopub.execute_input": "2025-07-20T19:41:28.395989Z",
     "iopub.status.idle": "2025-07-20T19:41:28.474765Z",
     "shell.execute_reply.started": "2025-07-20T19:41:28.395968Z",
     "shell.execute_reply": "2025-07-20T19:41:28.473868Z"
    },
    "ExecuteTime": {
     "end_time": "2025-07-24T09:42:31.017893257Z",
     "start_time": "2025-07-24T09:05:36.929426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "primary_activation = get_primary_activation(prompt_index)\n",
    "primary_activation = primary_activation.to(device)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-20T19:38:22.618850Z",
     "iopub.execute_input": "2025-07-20T19:38:22.619520Z",
     "iopub.status.idle": "2025-07-20T19:38:22.623666Z",
     "shell.execute_reply.started": "2025-07-20T19:38:22.619492Z",
     "shell.execute_reply": "2025-07-20T19:38:22.622837Z"
    },
    "ExecuteTime": {
     "end_time": "2025-07-24T09:42:31.019376489Z",
     "start_time": "2025-07-24T09:05:37.254289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target = torch.tensor([0], dtype=torch.float32)\n",
    "target = target.to(device)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-20T19:53:22.591342Z",
     "iopub.execute_input": "2025-07-20T19:53:22.591639Z",
     "iopub.status.idle": "2025-07-20T19:53:22.597902Z",
     "shell.execute_reply.started": "2025-07-20T19:53:22.591617Z",
     "shell.execute_reply": "2025-07-20T19:53:22.596870Z"
    },
    "ExecuteTime": {
     "end_time": "2025-07-24T09:42:31.020774461Z",
     "start_time": "2025-07-24T09:05:37.352174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_misclassification(adv_suffix):\n",
    "    device = custom_model.base_model.get_input_embeddings().weight.device\n",
    "    input_ids = suffix_manager.get_input_ids(adv_suffix).unsqueeze(0)\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    attention_mask = torch.ones_like(input_ids).to(device)\n",
    "\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "    last_token_activation = outputs['hidden_states'][-1][0, -1].float()  # poisoned activation with suffix\n",
    "\n",
    "    poisoned_activation = last_token_activation\n",
    "\n",
    "    delta = (poisoned_activation - primary_activation).detach().cpu().float().numpy().reshape(1, -1)\n",
    "\n",
    "    label = linear_model.predict(delta)\n",
    "    prob = linear_model.predict_proba(delta)\n",
    "    return label, prob"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "trusted": true,
    "_kg_hide-output": false,
    "execution": {
     "iopub.status.busy": "2025-07-20T19:41:32.241530Z",
     "iopub.execute_input": "2025-07-20T19:41:32.242025Z",
     "iopub.status.idle": "2025-07-20T19:53:16.344125Z",
     "shell.execute_reply.started": "2025-07-20T19:41:32.241991Z",
     "shell.execute_reply": "2025-07-20T19:53:16.343449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "not_allowed_tokens = None if allow_non_ascii else get_nonascii_toks(tokenizer)\n",
    "adv_suffix = adv_string_init\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(num_steps + 1):\n",
    "\n",
    "    # Step 1. Encode user prompt (behavior + adv suffix) as tokens and return token ids.\n",
    "    input_ids = suffix_manager.get_input_ids(adv_suffix)\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    # Step 2. Compute Coordinate Gradient\n",
    "    coordinate_grad, loss, outputs, one_hot = token_gradients(custom_model, input_ids, suffix_manager.adv_string_slice, target, primary_activation)\n",
    "    label, prob = check_misclassification(adv_suffix)\n",
    "    print(f\"i: {i}  loss: {loss:.10f}  {label}   {prob[0]}\")\n",
    "    print(adv_suffix)\n",
    "    print(\"-------------------------------------------------------\\n\")\n",
    "\n",
    "    if i == num_steps:\n",
    "        break\n",
    "\n",
    "    # Step 3. Sample a batch of new tokens based on the coordinate gradient.\n",
    "    # Notice that we only need the one that minimizes the loss.\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Step 3.1 Slice the input to locate the adversarial suffix.\n",
    "        adv_suffix_tokens = input_ids[suffix_manager.adv_string_slice].to(device)\n",
    "\n",
    "        # Step 3.2 Randomly sample a batch of replacements.\n",
    "        # Encoded suffixes\n",
    "        new_adv_suffix_tokens = sample_control(\n",
    "            adv_suffix_tokens,\n",
    "            coordinate_grad,\n",
    "            batch_size,\n",
    "            topk=topk\n",
    "        )\n",
    "\n",
    "        # Step 3.3 This step ensures all adversarial candidates have the same number of tokens.\n",
    "        # Decoded suffixes\n",
    "        new_adv_suffix = get_filtered_cands(\n",
    "            tokenizer,\n",
    "            new_adv_suffix_tokens,\n",
    "            filter_cand=True,\n",
    "            curr_control=adv_suffix\n",
    "        )\n",
    "\n",
    "        # Step 3.4 Compute loss on these candidates and take the argmin.\n",
    "        logits = get_logits(\n",
    "            custom_model=custom_model,\n",
    "            tokenizer=tokenizer,\n",
    "            input_ids=input_ids,\n",
    "            control_slice=suffix_manager.adv_string_slice,\n",
    "            primary_activation=primary_activation,\n",
    "            test_controls=new_adv_suffix,\n",
    "            return_ids=False,\n",
    "            batch_size=12 # decrease this number if you run into OOM.\n",
    "        )\n",
    "        target = target.to(logits.dtype)\n",
    "        expanded_target = target.expand_as(logits)\n",
    "\n",
    "        losses = nn.BCEWithLogitsLoss(reduction='none')(logits, expanded_target)\n",
    "\n",
    "        best_new_adv_suffix_id = losses.argmin()\n",
    "        best_new_adv_suffix = new_adv_suffix[best_new_adv_suffix_id]\n",
    "\n",
    "        adv_suffix = best_new_adv_suffix\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time} seconds\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
