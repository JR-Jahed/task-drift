import json
import logging
import os
import torch

from generate_activations.config.models import cache_dir, models

from generate_activations.activations import process_texts
from generate_activations.utils.model import load_model_and_tokenizer
import gc



# NOTE: Configuration
# Update the model name to the model you want to generate activations for (from models in task_tracker.config.models)
# Update with_priming to False if you want to generate activations without priming
# Update paths in task_tracker.config.models of cache_dir (HF cache dir),
# activation_parent_dir (the output of activations), and text_dataset_parent_dir (dir of dataset text files)

model_name: str = "phi3"
with_priming: bool = True


def main():
    model = models[model_name]
    model_path = os.path.join(cache_dir, model_name)

    try:
        # Load the model and tokenizer
        model_, tokenizer = load_model_and_tokenizer(
            model_path, torch_dtype=model.torch_dtype
        )
        model.tokenizer = tokenizer
        model.model = model_

        # Check if multiple GPUs are available
        if torch.cuda.device_count() > 1:
            logging.info(f"Let's use {torch.cuda.device_count()} GPUs!")

    except Exception as err:
        # Print memory summary for each GPU in case of an error
        for i in range(torch.cuda.device_count()):
            logging.info(f"Memory summary for GPU {i}:")
            logging.info(torch.cuda.memory_summary(device=i))
        raise err

    # Process data for activations
    for data_type, data in model.data.items():
        try:
            subset = json.load(open(data, "r"))

            suffix_list = json.load(open(model.suffix_list[data_type], "r"))

            # Determine directory and subset types based on data type
            if data_type == "train":
                directory_name = "training"
                process_texts(
                    dataset_subset=subset[model.start_idx :],
                    model=model,
                    data_type=data_type,
                    sub_dir_name=directory_name,
                    suffix_list=suffix_list['Suffix list'],
                    with_priming=with_priming,
                )
            else:
                directory_name = "validation" if "val" in data_type else "test"
                subset_type = "clean" if "clean" in data_type else "poisoned"
                process_texts(
                    dataset_subset=subset[model.start_idx :],
                    model=model,
                    data_type=subset_type,
                    sub_dir_name=directory_name,
                    suffix_list=suffix_list['Suffix list'],
                    with_priming=with_priming,
                )

        except json.JSONDecodeError as json_err:
            logging.error(f"Error decoding JSON for {data_type}: {json_err}")
        except Exception as data_err:
            logging.error(f"Error processing {data_type} data: {data_err}")

    del model.model
    del model.tokenizer

    gc.collect()
    torch.cuda.empty_cache()


if __name__ == "__main__":

    main()