import time
import pickle
from dataset import ActivationsDatasetDynamicPrimaryText
from utils.load_file_paths import load_file_paths
import numpy as np
import os
from constants import PROJECT_ROOT, LAYERS_PER_MODEL, ROOT_DIR_TEST
import torch
from adv_training.logistic_regression import LogisticRegression
import warnings


warnings.filterwarnings('ignore')
np.set_printoptions(suppress=True, linewidth=10000)

model = 'phi3'


def test_adv_trained_model(test_files_path, adv_training_type, num_layer):

    test_files = load_file_paths(test_files_path)

    linear_model = LogisticRegression(input_dim=3072)
    linear_model.load_state_dict(torch.load(os.path.join(PROJECT_ROOT, f'adv_trained_linear_probes_{adv_training_type}', model, str(num_layer), 'model.pt')))

    linear_model.eval()

    total_prompts = 31134
    poisoned_predicted = 0

    batch_files = 1

    for i in range(0, len(test_files), batch_files):

        # Test the linear model on a small subset of activations
        dataset = ActivationsDatasetDynamicPrimaryText(
            test_files[i: i + batch_files],
            root_dir=ROOT_DIR_TEST[model],
            num_layers=(num_layer, num_layer)
        )

        diff = []

        for primary, text in dataset:
            diff.append((text - primary).flatten().float())

        diff = torch.stack(diff)

        with torch.no_grad():
            logits = linear_model(diff)
            probs = torch.sigmoid(logits)

        predictions = (probs >= .5).long()
        poisoned_predicted += predictions.count_nonzero().item()

    if "clean" in test_files_path:
        print(f"Correct: {total_prompts - poisoned_predicted}  Test accuracy: {(total_prompts - poisoned_predicted) / total_prompts * 100:.2f}%")
    else:
        print(f"Correct: {poisoned_predicted}  Test accuracy: {poisoned_predicted / total_prompts * 100:.2f}%")


def test_microsoft_trained_model(test_files_path, num_layer):

    test_files = load_file_paths(test_files_path)

    total_prompts = 31134
    poisoned_predicted = 0

    linear_model = pickle.load(
        open(os.path.join(f'{PROJECT_ROOT}/trained_linear_probes_microsoft', model, str(num_layer), 'model.pickle'),
             'rb'))

    batch_files = 1


    for i in range(0, len(test_files), batch_files):

        # Test the linear model on a small subset of activations
        dataset = ActivationsDatasetDynamicPrimaryText(
            test_files[i : i + batch_files],
            root_dir=ROOT_DIR_TEST[model],
            num_layers=(num_layer, num_layer)
        )

        diff = []

        for primary, text in dataset:
            diff.append((text - primary).flatten().float().numpy())

        predict = linear_model.predict(diff)
        poisoned_predicted += np.sum(predict)

    if "clean" in test_files_path:
        print(f"Correct: {total_prompts - poisoned_predicted}  Test accuracy: {(total_prompts - poisoned_predicted) / total_prompts * 100:.2f}%")
    else:
        print(f"Correct: {poisoned_predicted}  Test accuracy: {poisoned_predicted / total_prompts * 100:.2f}%")


def check_model_consistency(test_files_path):

    """

    This function checks if all the binary classifiers predict the same label for a particular instance.
    Check the similarity of the last four classifiers too, since later layers' activations are more important in task drift detection.

    """

    test_files = load_file_paths(test_files_path)
    same_prediction_all_five_classifiers = 0
    same_prediction_last_four_classifiers = 0

    correct_classification_all_five_classifiers = 0
    correct_classification_last_four_classifiers = 0
    correct_classification_majority_classifiers = 0  # three or more

    for i in range(len(test_files)):
        prediction_across_layers = []
        for num_layer in LAYERS_PER_MODEL[model]:
            # Test the linear model on a small subset of activations
            dataset = ActivationsDatasetDynamicPrimaryText(
                test_files[i: i + 1],
                root_dir=ROOT_DIR_TEST[model],
                num_layers=(num_layer, num_layer)
            )

            diff = []

            for primary, text in dataset:
                diff.append((text - primary).flatten().float().numpy())

            linear_model = pickle.load(open(os.path.join(f'{PROJECT_ROOT}/trained_linear_probes_microsoft', model, str(num_layer), 'model.pickle'), 'rb'))
            predict = linear_model.predict(diff)

            prediction_across_layers.append(predict)

        for i in range(len(dataset)):
            if (prediction_across_layers[0][i] == prediction_across_layers[1][i]
                    == prediction_across_layers[2][i] == prediction_across_layers[3][i] == prediction_across_layers[4][i]):
                same_prediction_all_five_classifiers += 1

                if "clean" in test_files_path and prediction_across_layers[0][i] == 0:
                    correct_classification_all_five_classifiers += 1
                elif "poisoned" in test_files_path and prediction_across_layers[0][i] == 1:
                    correct_classification_all_five_classifiers += 1

            if (prediction_across_layers[1][i] == prediction_across_layers[2][i]
                    == prediction_across_layers[3][i] == prediction_across_layers[4][i]):
                same_prediction_last_four_classifiers += 1

                if "clean" in test_files_path and prediction_across_layers[1][i] == 0:
                    correct_classification_last_four_classifiers += 1
                elif "poisoned" in test_files_path and prediction_across_layers[1][i] == 1:
                    correct_classification_last_four_classifiers += 1

            poisoned_predicted = 0

            for j in range(5):
                poisoned_predicted += prediction_across_layers[j][i]

            if "poisoned" in test_files_path and poisoned_predicted >= 3:
                correct_classification_majority_classifiers += 1
            elif "clean" in test_files_path and poisoned_predicted < 3:
                correct_classification_majority_classifiers += 1

    print(f"Same prediction all five classifiers: {same_prediction_all_five_classifiers}"
          f"  ---  {same_prediction_all_five_classifiers / 31134 * 100:.2f}%")
    print(f"Same prediction last four classifiers: {same_prediction_last_four_classifiers}"
          f"  ---  {same_prediction_last_four_classifiers / 31134 * 100:.2f}%")
    print()

    print(f"Correct classification all five classifiers: {correct_classification_all_five_classifiers}"
          f"  ---  {correct_classification_all_five_classifiers / 31134 * 100:.2f}%")
    print(f"Correct classification last four classifiers: {correct_classification_last_four_classifiers}"
          f"  ---  {correct_classification_last_four_classifiers / 31134 * 100:.2f}%")
    print(f"Correct classification majority classifiers: {correct_classification_majority_classifiers}"
          f"  ---  {correct_classification_majority_classifiers / 31134 * 100:.2f}%")


def adv_trained_models_consistency(test_files_path, adv_training_type):

    test_files = load_file_paths(test_files_path)
    same_prediction_all_five_classifiers = 0
    same_prediction_last_four_classifiers = 0

    correct_classification_all_five_classifiers = 0
    correct_classification_last_four_classifiers = 0

    correct_classification_majority_classifiers = 0

    for i in range(len(test_files)):
        prediction_across_layers = []
        for num_layer in LAYERS_PER_MODEL[model]:
            # Test the linear model on a small subset of activations
            dataset = ActivationsDatasetDynamicPrimaryText(
                test_files[i: i + 1],
                root_dir=ROOT_DIR_TEST[model],
                num_layers=(num_layer, num_layer)
            )

            diff = []

            for primary, text in dataset:
                diff.append((text - primary).flatten().float())

            diff = torch.stack(diff)

            linear_model = LogisticRegression(input_dim=3072)
            linear_model.load_state_dict(torch.load(
                os.path.join(PROJECT_ROOT, f'adv_trained_linear_probes_{adv_training_type}', model, str(num_layer),
                             'model.pt')))

            with torch.no_grad():
                logits = linear_model(diff)
                probs = torch.sigmoid(logits)

            predictions = (probs >= .5).long()
            prediction_across_layers.append(predictions)

        for i in range(len(dataset)):
            if (prediction_across_layers[0][i] == prediction_across_layers[1][i]
                    == prediction_across_layers[2][i] == prediction_across_layers[3][i] == prediction_across_layers[4][i]):
                same_prediction_all_five_classifiers += 1

                if "clean" in test_files_path and prediction_across_layers[0][i] == 0:
                    correct_classification_all_five_classifiers += 1
                elif "poisoned" in test_files_path and prediction_across_layers[0][i] == 1:
                    correct_classification_all_five_classifiers += 1

            if (prediction_across_layers[1][i] == prediction_across_layers[2][i]
                    == prediction_across_layers[3][i] == prediction_across_layers[4][i]):
                same_prediction_last_four_classifiers += 1

                if "clean" in test_files_path and prediction_across_layers[1][i] == 0:
                    correct_classification_last_four_classifiers += 1
                elif "poisoned" in test_files_path and prediction_across_layers[1][i] == 1:
                    correct_classification_last_four_classifiers += 1

            poisoned_predicted = 0

            for j in range(5):
                poisoned_predicted += prediction_across_layers[j][i]

            if "poisoned" in test_files_path and poisoned_predicted >= 3:
                correct_classification_majority_classifiers += 1
            elif "clean" in test_files_path and poisoned_predicted < 3:
                correct_classification_majority_classifiers += 1

    print(f"Same prediction all five classifiers: {same_prediction_all_five_classifiers}"
          f"  ---  {same_prediction_all_five_classifiers / 31134 * 100:.2f}%")
    print(f"Same prediction last four classifiers: {same_prediction_last_four_classifiers}"
          f"  ---  {same_prediction_last_four_classifiers / 31134 * 100:.2f}%")
    print()

    print(f"Correct classification all five classifiers: {correct_classification_all_five_classifiers}"
          f"  ---  {correct_classification_all_five_classifiers / 31134 * 100:.2f}%")
    print(f"Correct classification last four classifiers: {correct_classification_last_four_classifiers}"
          f"  ---  {correct_classification_last_four_classifiers / 31134 * 100:.2f}%")
    print(f"Correct classification majority classifiers: {correct_classification_majority_classifiers}"
          f"  ---  {correct_classification_majority_classifiers / 31134 * 100:.2f}%")




if __name__ == '__main__':

    # check_model_consistency(f'{PROJECT_ROOT}/data_files/test_poisoned_files_{model}.txt')
    adv_trained_models_consistency(f'{PROJECT_ROOT}/data_files/test_poisoned_files_{model}.txt', 'suffix')
    exit(0)

    clean_filepath = f'{PROJECT_ROOT}/data_files/test_clean_files_{model}.txt'
    poisoned_filepath = f'{PROJECT_ROOT}/data_files/test_poisoned_files_{model}.txt'

    start_time = time.time()

    for num_layer in LAYERS_PER_MODEL[model]:

        print(f"Evaluating Layer {num_layer}\n")

        print("On clean dataset\n")
        print("Microsoft trained linear models:   -----   ", end='')
        test_microsoft_trained_model(clean_filepath, num_layer)

        print("Adversarially trained linear models:   -----   ", end='')
        test_adv_trained_model(clean_filepath, 'suffix', num_layer)

        print("-----------------------------------------")

        print("On poisoned dataset\n")
        print("Microsoft trained linear models:   -----   ", end='')
        test_microsoft_trained_model(poisoned_filepath, num_layer)

        print("Adversarially trained linear models:   -----   ", end='')
        test_adv_trained_model(poisoned_filepath, 'suffix', num_layer)

        print("----------------------------------------------------------------------------------------\n\n")

    print(f"Total time: {time.time() - start_time}")